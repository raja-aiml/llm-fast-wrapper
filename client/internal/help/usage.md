# ðŸ¤– LLM Client Usage

A simple CLI for interacting with OpenAI-compatible LLMs.

---

## ðŸ§ª Examples

### ðŸ”¹ One-off query (non-streaming)
Run a single prompt and exit.

```bash
go run client/main.go --query "Tell me a joke" --stream=false
```

### ðŸ”¹ Interactive mode (non-streaming)
Enter prompts interactively.

```bash
go run client/main.go --stream=false
```

### ðŸ”¹ Non-interactive (non-streaming)
Run a prompt in one-off mode using CLI flags.

```bash
go run client/main.go --query "Tell me a joke" --stream=false
```

---

âœ… **Tip:** Use `--stream=true` to enable streaming responses.